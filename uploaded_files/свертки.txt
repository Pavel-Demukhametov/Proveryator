Добрый день! Сегодня поговорим про сверточные нейронные сети и ответим на некоторые вопросы, которые возникали в чате, касающиеся не только сверточных нейронных сетей, но и вообще нейронных сетей. План на сегодня такой. Сначала поговорим про то, что такое, собственно, свертки, потом осветим некоторые особенности построения архитектуры сверточных нейронных сетей и рассмотрим особенности обучения сверточных нейронных сетей и не только, в том числе коснемся тех вопросов, которые были заданы в чате. И в конце поговорим о некоторых технических деталях обучения и о тех, можно сказать, курьезных случаях, когда сеть делала совсем не то, что нужно было делать. Давайте тогда перейдем к сверткам. На слайде, посвященном сверточным слоям введения, было рассказано, что это такое. Но мы сейчас более подробно коснемся разных параметров сверток и того, какие они в принципе бывают. Свертка — это операция, которая применяется к одноканальному... Не обязательно одноканальному, давайте пока считать, что одноканальному... К одноканальному изображению x на y, то есть у него есть какой-то размер, ширина и высота. И параметрами свертки является так называемое ядро. Это матрица, она может быть разных размеров. На семинаре мы рассматриваем очень подробно свертки с матрицами размера 3х3. Но в принципе это просто какая-то матрица, обычно квадратная, бывает еще и не квадратная. И в разные места исходной картинки эта матрица прикладывается. Дальше мы считаем, что элементы исходной картинки — это входы, как это, собственно, и есть. Элементы матрицы, которые называются ядром,, это веса. Мы домножаем по элементам элементы входной картинки на элементы ядра и складываем все, что получилось. И вот эту вот сумму взвешенную мы помещаем на следующий слой, то есть в следующую карту признаков, в следующую feature map. Так называемую. Ядра бывают разными в том числе они могут быть например сейчас давайте посмотрим эти картинки здесь синее изображение это исходное изображение, зеленое изображение это то, что получается после свертки, то есть это следующий фичемап, а темно-синее это, собственно, ядро свертки, которое прикладывается, в кавычках, к исходному изображению. И получается, что веса, которые есть в этом ядре, домножаются поэлементно на элементы исходного изображения. И чтобы получить следующий фичемап, следующую карту признаков, нам нужно ядро свертки переместить и приложить к всевозможным местам на исходном изображении. Здесь можно обратить внимание, что если приложить еще один такой же темно-синий квадрат уже к левому углу исходного изображения, то получится еще какое-то значение, которое будет соответствовать вот этому левому пикселю следующей карты признаков. То есть из размера следующей карты признаков в принципе следует что единственное возможное положение для ядра следующие слева это через два пикселя от того положения в котором она нарисована сейчас и это подводит нас вплотную к тому что такое страйт страйт это шаг с которым сдвигается ядро свертки между соседними его прикладываниями, между соседним вычислением взвешенной суммы. То есть обычная самая стандартная свертка производит движение ядра с шагом 1, сначала по иксу на 1, потом по игреку на 1. То есть мы проходим всевозможные положения вообще. А если сделать страйд не равным 1, например, равным 2, то ядро будет сдвигаться с шагом 2. При этом по иксу и по игреку может быть разный страйд в принципе. То есть PyTorch поддерживает и такое. Следующее дополнение к обычной свертке которую можно использовать это так называемый падинг если мы хотим преобразовать одну карту признаков в другую но при этом не уменьшить ее размер то мы можем дополнить по краям нашу карту признаков, исходную нулями. То есть, если бы... Ой, я камеру ногой задел, прошу прощения. Если бы... Страйт был один, если бы страйт был стандартный, то тогда мы смогли бы приложить... Мы смогли бы приложить ядро свертки вот в таком положении, потом в положении, когда оно занимало бы серединку левого нижнего ряда, и, наконец, в другом крайнем. То есть следующая карта признаков была бы размера 3х3, а исходная карта признаков была бы размера 5х5. То есть при использовании свертки без паддинга, без того, что изображено на средней картинке, размер фичмапа уменьшился бы. Если мы этого не хотим, то мы можем дополнить карту признаков нулями. И тогда размер изображения, собственно, не изменится. Есть такой подход, когда значения за границами карты признаков допол подряд друг за другом, а через один. То есть происходит то, что изображено на правой картинке. При размере ядра 3х3 в исходном изображении захватывается область размера 5 на 5. Мы просто пропускаем некоторые пиксели, и таким образом, за счет игнорирования некоторых элементов исходного изображения, мы увеличиваем, скажем так, охват. То есть мы можем, если изображение, например, имеет сравнительно низкую детализацию, если соседний пиксель там всегда очень близкий по цвету, а мы хотим подавать нейросеть именно такие картинки, то мы можем использовать дилатацию. Но это не только в таких случаях используется. В принципе, можно было бы просто уменьшать изображение перед подачей в нейросеть. И эти методы, конечно, можно комбинировать. И то, какой метод сработает лучше всего, можно узнать, как правило, с помощью практики. То есть просто попробовать одно и другое. Здесь важно обратить внимание на то, что каждая комбинация параметров дает свой собственный размер следующего фича мапа на один и тот же размер предыдущего фича мапа. То есть и страйт, и паддинг, и дилатация изменяют размеры следующей карты признаков. По тому адресу, который приведен снизу на слайде, можно посмотреть гифки с всеми вот этими методами и еще некоторыми другими дополнительными. Давайте пойдем дальше и посмотрим на простейший пример фильтра. Только не двумерный, а одномерный. То есть здесь то, что нарисовано снизу белыми квадратиками, это некий одномерный ряд. Давайте сначала посмотрим на левую половину. А то, что нарисовано справа, вот здесь, такая матрица 3х1, это ядро свертки. И мы берем вот это ядро свертки, прикладываем его вот сюда, к самой левой части. Домножаем 1 на 0, получаем 0, домножаем 0 на 1, получаем 0, домножаем минус 1 на 2, получаем минус 2, складываем 0 плюс 0 плюс минус 2, получаем минус 2. И вот мы вычислили значение по элементному произведению вот этого кусочка ряда входного вектора и вот этого ядра. Потом мы делаем то же самое со сдвигом на один, то есть просто прикладываем ядро вот сюда, также перемножаем, складываем, получаем другое значение. Делаем так для всех мест, в которых мы можем приложить ядро, и получаем следующую feature map. Справа приведен пример применения свертки с таким же ядром, только с шагом равным двойке. Почему это фильтр, выделяющий границы? Давайте посмотрим, как бы выглядели значения этого фильтра, если бы у нас была некоторая резкая граница, скажем, темных пикселей и белых пикселей. Там, где пиксели только темные, мы бы взяли темный пиксель, домножили его на единицу, потом взяли темный пиксель, домножили на 0, потом взяли такой же темный пиксель, домножили на минус 1, и за счет того, что цвета пикселей одинаковые, в результате получился бы 0. И цвет остался бы, точнее, не остался бы, он стал бы черным, он стал бы нулем. А если какая-то граница есть то просто значение соответствующие вот этим элементам совпадать не будут и здесь в результате на следующий фич маке мы получим значение разности между значениями пикселей. И если мы делаем это на границе, то мы получаем там значение разности между пикселями с двух сторон границы. Мы посмотрим в семинаре, как такой фильтр действует на цифры с десетом НИСТ, которого мы касались в прошлый раз. В процессе обучения нейронной сети те самые веса, то есть элементы ядра свертки обучаются. Так же, как и все остальные параметры которые обучаются в других слоях то есть к ним применяется метод обратного распространения ошибки backpropagation после того как они обучились они могут к примеру для какой-то задачи есть вот такой фильтр, который обходит все исходное изображение, и через домножение на него пикселей этого исходного изображения происходит получение следующей карты признаков с более какими-то высокоуровневыми фичами. Здесь на картинке приведен пример применения... Ну, тут сложно что-то разобрать, но просто можно отследить динамику. Тут приведен пример применения сверточной нейронной сети к изображению с машиной. Еще нужно сказать, что сверток может быть достаточно много, их может быть 32 штуки, 64 штуки. Если мы имеем на входе одно изображение с тремя каналами, то с помощью сверток мы можем перевести это изображение в, например, 32 канала, как это происходит. Просто у фильтров, у этих сверток, добавляется еще одна размерность, и мы прикладываем к фактически трехмерному тензору с числами, к исходному изображению ядро свертки, располагая его в каких-то координатах по ху и у, и при этом занимая всю его глубину, все три канала цветовых, тремя разными двумерными ядрами. И вот если таких трехмерных ядер мы возьмем 32 штуки, то получится, что у нас трехканальное входное изображение преобразуется в 32-канальное выходное изображение. Ну или можно сказать, что 3 одноканальных изображения преобразуется в 32 одноканальных изображения. Это, в принципе, одно и то же. Здесь на слайде можно обратить внимание, что при движении вправо с каждым следующим фильтром размер исходного изображения уменьшается. То есть вот слева у нас исходная картинка с машиной, дальше что-то похожее на машину, а справа что-то уже совсем на машину не похоже, это просто какое-то низкополигональное изображение, изображение из маленького количества пикселей, в котором уже машина ничего особо не напоминает. Как это происходит? И за счет чего это получается? Здесь вот можно обратить внимание, стоит сверточный слой, потом активация, сверточный слой активации, и вот здесь стоит так называемый пулинг. О пулинге мы сейчас как раз и поговорим пулинг это уменьшение размера изображения которое производится за счет замены группы пикселей на какую-то функцию от этой группы пикселей то есть простейший случай это max pooling когда мы из группы пикселей. То есть простейший случай это MaxPooling, когда мы из группы пикселей вытаскиваем максимум по ним и помещаем его на следующую карту признаков. И опять же простейший случай MaxPooling это MaxPooling 2х2. То есть предположим, что у нас есть некоторые изображения 4х4, и мы делим его на 4 квадрата 2х2, и в каждом квадрате просто выбираем максимальное значение и его перемещаем на следующий слой. Что это нам дает? Во-первых, это позволяет уменьшить, в данном случае в 4 раза, количество пикселей, которые у нас есть в feature map. Исходные изображения, которые приходят, если это картинки, достаточно большие. То есть Full HD картинка — это порядка нескольких миллионов значений, а в результате мы хотим получить на самом деле, например, в случае классификации, всего несколько чисел, то есть вектор из вероятностей, и их вряд ли там будет несколько миллионов штук, то есть мы должны каким-то образом сильно уменьшать размерность. При этом нам нужно уменьшать размерность таким образом, чтобы не терялась информация. Не терять информацию фактически означает выделять из всей информации наиболее важную для нас информацию. Наиболее важны для нас, как правило, какие-то или яркие, или граничные элементы. Если мы, скажем, применим MaxPooling к изображению с окружностью, то окружность после MaxPooling, белая окружность на темном фоне, по-прежнему останется окружностью. Если бы мы вместо MaxPooling сделали, например, AveragePooling, то есть перенос на следующий FitchMap среднего значения по группе пикселей, то эта окружность стала бы гораздо менее яркой. А если мы вытаскиваем на следующий слой максимум, то окружность ост бы гораздо менее яркой. А если мы вытаскиваем на след числа и максимум, то окружность остается окружностью. И таким образом, за счет того, что мы сохраняем или увеличиваем интенсивность границ, мы можем при уменьшении суммарного размера векторов сохранять значительную часть полезной информации, которая в них содержится. Вот так выглядит архитектура детектора YOLO, который будет рассмотрен на одном из следующих семинаров. Собственно, практически весь семинар будет посвящен детекторам, и в частности Йола. И здесь видно, что он практически целиком, этот детектор построен из сверточных слоев. То есть по мере движения от исходного изображения, который находится слева к выходному вектору, который находится справа, изображение становится меньше по пространственным координатам. Сначала они 448 на 448 потом они становятся 112 на 112 и помимо этого увеличивается постоянно количество слоев то есть сначала слоев 3 красный зеленый синий потом и сенсы 192 у них уже никаких названий таких нет то есть они просто никак не интерпретируется но можно сказать что мы уменьшаем количество признаков мы наоборот увеличиваем количество признаков и уменьшаем по пространственным координатам те карты на которых они содержатся то есть в исходном изображении таких признаков для каждого пикселя 3. Это три цветовых канала, количество красного, зеленого и синего. А дальше это уже карты признаков, каких-то более сложных, для которых нет устаившихся названий. Есть такой метод до обучения нейронных сетей. Он применяется в случае, когда, например, данных какого-то специфического типа у нас очень мало или совсем нет, но при этом у нас есть нейросеть, которая обучена уже на данных каких-то похожих на те, которые нас интересуют. К примеру, у нас есть хорошо работающий классификатор животных, который распространен широко. Широко распространены, например, кошки, собаки, кто-нибудь еще в таком духе. А носороги, например, распространены не настолько широко. И мы хотим построить классификатор носорогов. Значит, мы можем или бегать за носорогами и собирать большой датасет, пытаться это делать, или мы можем взять классификатор, который обучен на что-то другое, и немного его дообучить так, чтобы он начал работать на носорогах. Давайте ненадолго вернемся к слайду с YOLO. Можно условно разделить сеть на две половины. Первая половина вытаскивает из исходного изображения некоторые его характеристики, так называемые фичи, признаки. А вторая половина на основе этих фичей, на основе этих признаков, дает, собственно, ответ. То есть или класс, к которому принадлежит объект, или в случае YOLA это будет bounding box, то есть прямоугольник ограничивающий объект. Можно так условно разделить сеть на две части. Первая из них описывает компактным образом объект, а вторая на основе этого компактного описания строит, собственно, предсказание того что нам нужно и если мы знаем что все животные состоят из плюс-минус одинаковых элементов усы лапы хвост кожи ноги вот это вот все то есть какая-то комбинация какая-то комбинация уже имеющихся у нас признаков. Мы можем любое животное с какой-то точностью приблизить через описание других животных. Там собачка, это кошечка минус мышка, вот в таком духе. То есть компоненты там те же самые, у них просто другие, друг в другом соотношения, это другая композиция. И если мы не будем трогать первую половину сети, то есть те слои, которые ответственны за построение компактного описания объекта, то мы можем пропустить очень длинный процесс обучения сети вот этому самому выделению признаков мы можем получить короткое векторное описание объекта из первой половины которая осталась неизменной а вот вторую половину можем переобучить под новую задачу вот это называется до обучения или так называемый fine tuning когда данных мало или их очень сложно найти или для того чтобы эти данные получить нужно чем сломать в таких случаях когда данные достаточно очень сложно можно на имеющемся маленьком количестве данных до обучать уже работающие сети, а конкретно их вторую половину. Был вопрос про то, что такое batch normalization. Batch normalization это, если мы вернемся к разговору о batch, который был на прошлой лекции, это приведение всех изображений в batch к нулевому среднему и к единичной дисперсии. То есть мы считаем для того, что у нас пришло на вход для вектора x картинки на y картинки на глубину картинки на размер батча, для этого мы считаем так чтобы у всего батча среднее было равно нулю дисперсия была равна единице и это позволяет при условии того что бач нормализация при том что нормализация бача остается также и после обучения то есть на ин на Inference, когда мы уже применяем модель, она тоже применяется. Это позволяет достичь того, что распределение на входе всегда плюс-минус одинаковое. То есть можно сказать, что просто данные становятся более однородными, и защитат его сеть учится быстрее и в результате работает стабильнее был вопрос про то что такое или lr shadler напомню что learning rate или lr это шаг с которым мы обновляем веса модели, максимальный шаг. Обычно он там в районе 1,1 или 1,1. И чем больше этот LR, если он для всего периода обучения одинаковый, тем, с одной стороны, быстрее сеть учится, то есть быстрее сходится к оптимуму. Но с другой стороны, тем сложнее ей внутри маленькой окрестности локального минимума некоторого найти самую оптимальную точку. Это изображено как раз на рисунке. То есть если у нас большой шаг, большой learning rate, то мы сначала довольно быстро двигаемся к минимуму, а потом вокруг него как-то пляшем и никак не можем к нему сойтись. Есть решение этой проблемы. Решение состоит в том, что learning rate уменьшается в процессе обучения. То есть сначала он большой, мы находим какой-то минимум на достаточно больших масштабах, а потом его уменьшаем и начинаем искать более локальный минимум, заниматься более тонкой настройкой весов. Есть разные стратегии, разные подходы к уменьшению learning rate. Самое простое из них состоит в том, что он уменьшается просто в константное число раз на каждой эпохе. То есть, сначала он был, например, 1 десятая, а потом домножается на 999 тысячных. И, в конце концов, уменьшается достаточно сильно. Более сложная, более адаптивная стратегия состоит в том, чтобы отслеживать результаты обучения текущие и, например, смотреть на то, в течение какого количества эпох не обновлялся минимальный лосс. Если минимальный лосс не обновлялся в течение, например, 5 эпох, можно сказать, что мы достигли некоторого предела обучения при условии сохранения текущего learning rate, это значит, что мы можем learning rate уменьшить и заняться более тонкой подстройкой весов. То есть, в случае, когда в течение пяти эпох лосс не уменьшался, можно считать в каком-то смысле эквивалентным таким переходом с одной стенки этого графика на другую стенку без достижения минимума при этом если мы зафиксируем и уменьшим learning rate то тогда можно будет с помощью викторков поменьше просто сойтись в более низкую точку на этом график на Ну, вверх тут, конечно, лосс отложен. Вот. Лоссы бывают разные. Был очень верный вопрос в чате про то, как их можно выбирать вообще и для каких задач, я, по крайней мере, так этот вопрос понял, для каких задач какие лоссы подходят. Представим себе, что мы решаем задачу восстановления изображения из какого-то внутреннего представления. То есть мы его сначала сеткой сжали, а потом сеткой же хотим разжать. И если мы используем lossL2, то есть minSquareError, сумму квадратичных ошибок, то представим себе, что произойдет на границе, например, белого и черного регионов на изображении. Если на границе значение будет ошибочно белым, то есть на самом деле на черное, а сеть выдала там, что ответ должен быть белым, то в loss этот пиксель перейдет с каким-то своим вкладом. Назовем его, например, L. А если вместо этого сказать, что там находится среднее между черным и белым, то вклад этого пикселя в loss будет L делить на 4. И поскольку нейросеть оптимизирует LOS функцию, собственно, более выгодно... Более выгодно действительно выбирать не крайние какие-то значения, а средние значения на границах. Это приводит к тому, что при использовании лосс l2 границы всегда становятся размытыми потому что фигурально выражаясь это более безопасная стратегия то есть она позволяет локально минимизировать лосс при том что визуальное качество воспринимаемого выхода оказывается ниже, чем могло бы быть. На картинке изображена задача сегментации. Слева исходное изображение, это клетки под микроскопом. А справа границы этих клеток, которые, собственно, нужно было выделить. И если использовать здесь лосс, например, L2 или L1, или какой-то такой обычный картиночный лосс, то за счет того, что есть большой дисбаланс черных и белых пикселей в выходе, наиболее безопасной, ну, то есть, можно сказать, что оптимальной стратегией было бы просто выдавать черный выход все время потому что это более выгодно если выдать один ошибочный черный пиксель то вклад в лосс будет маленький а если выдать один ошибочный белый пиксель то вклад в LOS его будет большой. Ой, прошу прощения. Я ошибся. Вклад у них будет одинаковый, просто вероятность угадать белый пиксель гораздо ниже, чем вероятность угадать черный пиксель. Вот в чем дело, я извинюсь. Вот. И поэтому, если использовать обычный пиксель. Вот в чем дело, я извиняюсь. Вот и поэтому, если использовать обычный Loss L2, в этом случае мы с высокой вероятностью получим просто черную картинку на выходе. Это подводит нас к тому, что выбор Loss для обучения определяется задачей, конечно же. И если мы хотим получать правильную сегментацию, то есть границы объектов получать, то мы можем использовать для решения этой задачи loss под названием Intersection over Union или EOU. Для подсчета его значения мы берем и делим площадь пересечения ответа модели и правильного ответа на площадь объединения того же самого. Получается, что если они полностью совпадают, то значение такой функции intersection over union равно единице. Если они пересекаются по половинке, то оно равно, получается, 1 третий. А, ну, там с минусом, на самом деле, нужно его взять тогда, чтобы минимизировать. Да. Вот. То есть мы имеем два каких-то объекта, их попиксельно пересекаем, считаем площадь, потом объединяем, считаем площадь и пересечение делим на объединение. Есть вот такой еще лосс. Есть так называемый Perceptual Loss. не изображений, а промежуточных представлений, высоковыровневых, то есть представлений, которые отвечают некоторым характеристикам изображения, таким как наличие на них объектов, например. Или если речь идет о классификации текстур, о каких-то достаточно высоковыровневых параметрах текстуры. То есть здесь речь идет о том, чтобы применять функции нахождения близости не к выходам сети, а к чему-то, что находится в ее середине. Там, где мы получаем некоторые высокоуровневые представления объекта, мы можем посчитать, насколько это представление, скажем, близко к распределению тех представлений, которые нас интересуют. Ну, например, если мы занимаемся задачей стайл-трансфера, то есть если мы хотим рисовать как Пикассо, мы можем взять и с помощью зафиксированной модели, вычисляющей промежуточное представление изображения, найти насколько похоже одно промежуточное представление изображения на другое промежуточное представление и есть наконец так называемые композитные лосы над просто суммы какие-то взвешенные разных лосов то есть если нас интересует не только изображение а еще и скажем его граница, если мы хотим достаточно точно восстанавливать границы, которые, собственно, человек при своем восприятии и замечает более всего, то мы можем ввести отдельный лосс на границах. То есть один лосс — это, например, L2 на всех картинках, а второй лосс — это, например, L2 на всех картинках, а второй loss — это, например, L2 на границах. То есть мы можем сначала найти границы с помощью того сверточного фильтра, который был несколько слайдов назад. А после этого мы можем к нему и к такому же изображению, построенному для правильного ответа, применить L2, дистанцию, L2 расстояние для них посчитать. И тогда получается, что мы будем восстанавливать, если решить идет о такой задаче, не только картинку, и не только ее абсолютное значение, но еще и границы будем стараться восстанавливать. Всегда важно помнить, что сеть не ошибается, что она делает ровно то, что ей сказали. Но наше мнение о том, что мы ей сказали, и то, что мы сказали ей на самом деле, может различаться. То есть происходит оптимизация некоторой функции на некотором наборе данных, и не всегда очевидно, как можно поставить задачу, то есть что именно произойдет при оптимизации этой функции. Есть такой каноничный случай классификации собак, когда любая собака на снегу классифицировалась как хаски. Потому что обычно на снегу, на фотографиях в интернетике, встречаются именно такие собаки. То есть признаки, которые научилась видеть эта сеть, были заключены не в самой собаке, а в том, что вокруг собаки находилась. И есть еще один пример. Решали задачу классификации спутниковых снимков на два класса. На снимке, на которых есть танки, и на снимке, на которых нет танков. И вот на трейне сеть обучилась просто идеально. То есть она с очень высокой вероятностью маркировала изображения, как или содержащие танки, или не содержащие танки. А когда взяли какие-то настоящие изображения, которые до этого ни исследователями, ни сетью увидены не были, там скоры были очень низкие, то есть результаты были близки к шуму. Стали думать, в чем же дело, и после некоторых поисков выяснилось, что на тех изображениях, где есть танки, просто были снизу нарисованы маленькие крестики карандашом. Таким образом были помечены эти картинки, и это не заметили перед обучением, и поэтому сеть, которая была архитектурно достаточно сложной и предназначенной для решения задачи по-честному, то есть для нахождения танков, которые могут быть там как-то плохо видны или скрыты, вот такая большая сложная сеть, просто идеально научилась решать задачу нахождения крестиков в углу картинки. На этом все на сегодня. Спасибо за внимание.